# GRADIENT-DESCENT-NEURAL-NETWORK
Gradient Descent

Gradient Descent is an optimization algorithm used in machine learning and deep learning to minimize the cost function. Its main goal is to update the model's weights in such a way that the cost function (which measures the difference between the model's predictions and the actual values) is minimized. The weights are updated in small steps based on the gradient, and this step size is controlled by the learning rate.
Neural Networks

Neural Networks are deep learning models that simulate the functioning of the human brain. They consist of layers of neurons that process inputs to generate outputs. During training, data is passed through the network to make predictions (forward propagation), and then errors are adjusted using backward propagation. The weights are updated using gradient descent, enabling the network to learn complex patterns and make accurate predictions.
